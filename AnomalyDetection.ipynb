{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.139558</td>\n",
       "      <td>-2.663727</td>\n",
       "      <td>3.371479</td>\n",
       "      <td>4.353534</td>\n",
       "      <td>1.482218</td>\n",
       "      <td>-0.579998</td>\n",
       "      <td>-0.614653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.008677</td>\n",
       "      <td>-1.475652</td>\n",
       "      <td>-0.154210</td>\n",
       "      <td>-0.111862</td>\n",
       "      <td>-0.067099</td>\n",
       "      <td>-0.579998</td>\n",
       "      <td>-0.614653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.877796</td>\n",
       "      <td>-1.428876</td>\n",
       "      <td>-0.193579</td>\n",
       "      <td>-0.111862</td>\n",
       "      <td>-0.067099</td>\n",
       "      <td>-0.579998</td>\n",
       "      <td>-0.614653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.746916</td>\n",
       "      <td>-1.397691</td>\n",
       "      <td>-0.269529</td>\n",
       "      <td>-0.111862</td>\n",
       "      <td>-0.067099</td>\n",
       "      <td>-0.579998</td>\n",
       "      <td>-0.614653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.616035</td>\n",
       "      <td>-1.392406</td>\n",
       "      <td>-0.236393</td>\n",
       "      <td>-0.111862</td>\n",
       "      <td>-0.067099</td>\n",
       "      <td>-0.579998</td>\n",
       "      <td>-0.614653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0 -1.139558 -2.663727  3.371479  4.353534  1.482218 -0.579998 -0.614653\n",
       "1 -1.008677 -1.475652 -0.154210 -0.111862 -0.067099 -0.579998 -0.614653\n",
       "2 -0.877796 -1.428876 -0.193579 -0.111862 -0.067099 -0.579998 -0.614653\n",
       "3 -0.746916 -1.397691 -0.269529 -0.111862 -0.067099 -0.579998 -0.614653\n",
       "4 -0.616035 -1.392406 -0.236393 -0.111862 -0.067099 -0.579998 -0.614653"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('PreProcessingAnomaly/df_train.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duppu\\AppData\\Local\\Temp\\ipykernel_8836\\3249373429.py:9: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_k_folds(df, k):\n",
    "    k_size = int(len(df)/k)\n",
    "\n",
    "    k_folds = []\n",
    "    for i in range(k):\n",
    "        k_folds.append(df[i*k_size:(i+1)*k_size])\n",
    "\n",
    "    # Append any remaining rows to the last fold\n",
    "    k_folds[-1] = k_folds[-1].append(df[k*k_size:])\n",
    "\n",
    "    return k_folds\n",
    "\n",
    "k_folds = split_k_folds(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models used:\n",
    "# 1. Isolation Forest\n",
    "# 2. Local Outlier Factor\n",
    "# 3. One Class SVM\n",
    "# 4. Robust Covariance Estimation\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "def create_models(df, k_folds, method):\n",
    "    \"\"\"\n",
    "    Creates a parent model using the algorithm in method and k-child models using the same algorithm.\n",
    "    Parent model is trained on all data except.\n",
    "    Child models are trained on each k-fold of data.\n",
    "\n",
    "    Parameters:\n",
    "    df: Pandas DataFrame\n",
    "        The entire dataset\n",
    "    k_folds: List\n",
    "        List of k-folds of the dataset\n",
    "    method: sklearn model\n",
    "        The model to be used\n",
    "\n",
    "    Returns:\n",
    "    parent_model: sklearn model\n",
    "        The parent model\n",
    "    child_models: List\n",
    "        List of k child models\n",
    "    \"\"\"\n",
    "    parent_model = method\n",
    "    parent_model.fit(df)\n",
    "\n",
    "    child_models = []\n",
    "    for i in range(len(k_folds)):\n",
    "        child_models.append(method)\n",
    "        child_models[i].fit(k_folds[i])\n",
    "\n",
    "    return parent_model, child_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duppu\\miniconda3\\envs\\DP4\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:184: RuntimeWarning:\n",
      "\n",
      "Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.375622163604703 > -185.840273408883661). You may want to try with a higher value of support_fraction (current value: 0.898).\n",
      "\n",
      "c:\\Users\\duppu\\miniconda3\\envs\\DP4\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:184: RuntimeWarning:\n",
      "\n",
      "Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.375622163604703 > -187.833162049463084). You may want to try with a higher value of support_fraction (current value: 0.898).\n",
      "\n",
      "c:\\Users\\duppu\\miniconda3\\envs\\DP4\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:184: RuntimeWarning:\n",
      "\n",
      "Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.375622163604703 > -185.793870461872359). You may want to try with a higher value of support_fraction (current value: 0.898).\n",
      "\n",
      "c:\\Users\\duppu\\miniconda3\\envs\\DP4\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:184: RuntimeWarning:\n",
      "\n",
      "Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.375622163604703 > -189.760122787115023). You may want to try with a higher value of support_fraction (current value: 0.898).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Models:\n",
    "    def __init__(self, df, k_folds, methods):\n",
    "        self.df = df\n",
    "        self.k_folds = k_folds\n",
    "        self.methods = methods\n",
    "\n",
    "    def instantiate_models(self):\n",
    "        \"\"\" \n",
    "        Instantiates all models and child models\n",
    "        \"\"\"\n",
    "        models = {}\n",
    "        for method in self.methods:\n",
    "            # Create string name of model\n",
    "            model_name = str(method).split('(')[0]\n",
    "            parent_model, child_models = create_models(self.df, self.k_folds, method)\n",
    "            models[model_name] = {\n",
    "                'parent_model': parent_model,\n",
    "                'child_models': child_models,\n",
    "                'weights': 1\n",
    "            }\n",
    "        self.models = models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CICS is the weighted average of the Internal Consensus Score (ICS) as expressed:\n",
    "\n",
    "$F_x^c = \\frac{1}{M}\\sum_{i=1}^M I_x^i * w_i$\n",
    "\n",
    "where $M$ is the number of models, $I_x^i$ is the ICS of model $i$ for the $x$-th data point, and $w_i$ is the weight of model $i$.\n",
    "\n",
    "The ICS expressed is inspired by Bagging approach in machine learning. The training data is split randomly into k-folds. A k-child models are created for each model in the ensemble. The k-child models are trained each with one separate fold out of the k-fold training data. The votes a data point receives from the k-child models are termed as the Internal Consensus Vote (ICV). A data point is considered an inlier by a model if it has 1 or more ICV.\n",
    "\n",
    "$I_x = \\frac{1}{k}\\sum_{i=1}^k v$\n",
    "\n",
    "where $v$ is the number of votes x recieved as an inlier from the k-child models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute internal consensus score\n",
    "def compute_icv_ics(child_models, data_point):\n",
    "    \"\"\"\n",
    "    Computes the internal consensus vote (ICV) and internal consensus score (ICS) for each data point in the training data.\n",
    "\n",
    "    Parameters:\n",
    "    child_models: List\n",
    "        List of child models\n",
    "    data_point: Pandas DataFrame row\n",
    "        A single row of the training data\n",
    "\n",
    "    Returns:\n",
    "    icv: int\n",
    "\n",
    "    \"\"\"\n",
    "    votes = []\n",
    "    for child_model in child_models:\n",
    "        votes.append(child_model.predict([data_point]))\n",
    "\n",
    "    # Compute internal consensus score\n",
    "    ics = sum(votes) / len(votes)\n",
    "\n",
    "    if ics >= 0:\n",
    "        icv = 1\n",
    "    else:\n",
    "        icv = 0\n",
    "\n",
    "    return icv, ics\n",
    "\n",
    "\n",
    "def compute_cics(models, data_point):\n",
    "    \"\"\"\n",
    "    Computes the consensus internal consensus score (CICS) for each data point in the training data.\n",
    "\n",
    "    Parameters:\n",
    "    models: List\n",
    "        List of models\n",
    "    data_point: Pandas DataFrame row\n",
    "        A single row of the training data\n",
    "\n",
    "    Returns:\n",
    "    ICV: List\n",
    "        List of internal consensus votes\n",
    "    CICS: float\n",
    "        The consensus internal consensus score\n",
    "    \"\"\"\n",
    "    # Compute internal consensus score for each child model\n",
    "    combined_score = []\n",
    "    ICV = []\n",
    "    total_weights = 0\n",
    "    for model in models:\n",
    "        icv, ics = compute_icv_ics(models[model]['child_models'], data_point)\n",
    "        ICV.append(icv)\n",
    "        combined_score.append(ics * models[model]['weights'])\n",
    "        total_weights += models[model]['weights']\n",
    "\n",
    "    CICS = sum(combined_score) / len(models)\n",
    "\n",
    "    return ICV, CICS\n",
    "\n",
    "\n",
    "def compute_cecs(models, data_point):\n",
    "    \"\"\"\n",
    "    Computes the consensus external consensus score (CECS) for each data point in the training data.\n",
    "\n",
    "    Parameters:\n",
    "    models: List\n",
    "        List of models\n",
    "    data_point: Pandas DataFrame row\n",
    "        A single row of the training data\n",
    "\n",
    "    Returns:\n",
    "    CECV: int\n",
    "        The consensus external consensus vote\n",
    "    CECS: float\n",
    "        The consensus external consensus score\n",
    "    \"\"\"\n",
    "    # Compute external consensus score for each model\n",
    "    combined_score = []\n",
    "    for model in models:\n",
    "        # Predict data point using parent model\n",
    "        ecs = models[model]['parent_model'].predict([data_point])\n",
    "\n",
    "        combined_score.append(ecs)\n",
    "\n",
    "    CECS = sum(combined_score) / len(models)\n",
    "\n",
    "    if CECS >= 0:\n",
    "        CECV = 1\n",
    "    else:\n",
    "        CECV = 0\n",
    "\n",
    "    return CECV, CECS\n",
    "\n",
    "\n",
    "def calculate_weights(CECV_all, ICV_all, models):\n",
    "    \"\"\"\n",
    "    Calculates the weights for each model.\n",
    "\n",
    "    Parameters:\n",
    "    CECV_all: List\n",
    "        List of consensus external consensus votes\n",
    "    ICV_all: List of Lists\n",
    "        List of internal consensus votes\n",
    "    models: Models object\n",
    "        Models object\n",
    "    \n",
    "    Returns:\n",
    "    models: Models object\n",
    "        Updated models object\n",
    "    \"\"\"\n",
    "    model_names = list(models.models.keys())\n",
    "\n",
    "    errors = np.zeros(len(model_names))\n",
    "\n",
    "    for xi in range(len(CECV_all)):\n",
    "        Vi = CECV_all[xi]\n",
    "        ICV = ICV_all[xi]\n",
    "        for vi in ICV:\n",
    "            if vi != Vi:\n",
    "                errors[ICV.index(vi)] += 1\n",
    "    print('\\n --------------------- \\nUpdating weights\\n ---------------------')\n",
    "\n",
    "    for model in model_names:\n",
    "        # w_f = w_i * (e / n) * w_i\n",
    "        weight_i = models.models[model]['weights']\n",
    "        error_i = errors[model_names.index(model)]\n",
    "        n = len(CECV_all)\n",
    "        weight_f = weight_i - (error_i / n) * weight_i\n",
    "        \n",
    "        print('Model {} performance: {}/{}. Weight: {} -> {}'.format(model, n - error_i, n, weight_i, weight_f))\n",
    "\n",
    "        models.models[model]['weights'] = weight_f\n",
    "\n",
    "\n",
    "    return models\n",
    "    \n",
    "\n",
    "def train_ensemble(models, df_train):\n",
    "    \"\"\"\n",
    "    Iterates through the training data and compute the CICS, CECS and ICV for each data point. \n",
    "    The weights for each model are then updated.\n",
    "    \"\"\"\n",
    "    print('Training ensemble...')\n",
    "    ICV_all = []\n",
    "    CECV_all = []\n",
    "\n",
    "    for i in range(len(df_train)):\n",
    "    # for i in range(20):\n",
    "        print('Training data point: {}/{}'.format(i+1, len(df_train)), end='\\r')\n",
    "\n",
    "        data_point = df_train.iloc[i]\n",
    "        ICV, CICS = compute_cics(models.models, data_point)\n",
    "        ICV_all.append(ICV)\n",
    "        CECV, CECS = compute_cecs(models.models, data_point)\n",
    "        CECV_all.append(CECV)\n",
    "\n",
    "    # Update weights\n",
    "    models = calculate_weights(CECV_all, ICV_all, models)\n",
    "    print('Training complete. \\n ------------------')\n",
    "    return models\n",
    "\n",
    "\n",
    "def perform_CNDE(models, df_train):\n",
    "    \"\"\"\n",
    "    Performs the CNDE algorithm on the training data.\n",
    "\n",
    "    Parameters:\n",
    "    models: List\n",
    "        List of models\n",
    "    df_train: Pandas DataFrame\n",
    "        Training data\n",
    "\n",
    "    Returns:\n",
    "    models: List\n",
    "        List of models\n",
    "    \"\"\"\n",
    "    # Train ensemble\n",
    "    models = train_ensemble(models, df_train)\n",
    "\n",
    "    normality_scores = []\n",
    "    all_CICS = []\n",
    "    all_CECS = []\n",
    "    # Calculate normality score\n",
    "    for i in range(len(df_train)):\n",
    "    # for i in range(20):\n",
    "        print('Calculating normality score: {}/{}'.format(i+1, len(df_train)), end='\\r')\n",
    "        data_point = df_train.iloc[i]\n",
    "        ICV, CICS = compute_cics(models.models, data_point)\n",
    "        CECV, CECS = compute_cecs(models.models, data_point)\n",
    "\n",
    "        all_CICS.append(CICS)\n",
    "        all_CECS.append(CECS)\n",
    "\n",
    "        # Calculate normality score\n",
    "        N = (CICS + CECS) / 2\n",
    "        normality_scores.append(N)\n",
    "\n",
    "    models.normality_scores = normality_scores\n",
    "    models.all_CICS = all_CICS\n",
    "    models.all_CECS = all_CECS\n",
    "    models.weights = [models.models[model]['weights'] for model in models.models]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble...\n",
      "Training data point: 1477/1477\n",
      " --------------------- \n",
      "Updating weights\n",
      " ---------------------\n",
      "Model IsolationForest performance: 1193.0/1477. Weight: 1 -> 0.8077183480027081\n",
      "Model LocalOutlierFactor performance: 1346.0/1477. Weight: 1 -> 0.9113067027758971\n",
      "Model OneClassSVM performance: 1419.0/1477. Weight: 1 -> 0.960731211916046\n",
      "Model EllipticEnvelope performance: 1443.0/1477. Weight: 1 -> 0.976980365605958\n",
      "Training complete. \n",
      " ------------------\n",
      "Calculating normality score: 1477/1477\r"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    IsolationForest(contamination=0.1),\n",
    "    LocalOutlierFactor(novelty=True, contamination=0.1),\n",
    "    OneClassSVM(nu=0.1),\n",
    "    EllipticEnvelope(support_fraction=0.95, contamination=0.1)\n",
    "]\n",
    "models = Models(df, k_folds, methods)\n",
    "models.instantiate_models()\n",
    "\n",
    "models = perform_CNDE(models, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality scores: [0. 1. 1. ... 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# List of arrays to single array\n",
    "def flatten_list(l):\n",
    "    \"\"\"\n",
    "    Flattens a list of arrays into a single array.\n",
    "\n",
    "    Parameters:\n",
    "    l: List\n",
    "        List of arrays\n",
    "\n",
    "    Returns:\n",
    "    flat_list: List\n",
    "        Single array\n",
    "    \"\"\"\n",
    "    flat_list = []\n",
    "    for sublist in l:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "normality_scores = flatten_list(models.normality_scores)\n",
    "# Scale normality scores to range 0-1\n",
    "normality_scores = (normality_scores - min(normality_scores)) / (max(normality_scores) - min(normality_scores))\n",
    "print('Normality scores: {}'.format(normality_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame(normality_scores, columns=['Normality score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "size": 3
         },
         "mode": "markers",
         "name": "Normality Scores",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476
         ],
         "y": [
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7503758068794766,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0.7439207710672916,
          0.7439207710672916,
          1,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.23609514545936866,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0.7439207710672916,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          0.7503758068794766,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.23609514545936866,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.23609514545936866,
          1,
          1,
          1,
          1,
          0,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          1,
          0.5057034220532319,
          0.25607922893270846,
          1,
          0.25607922893270846,
          0,
          1,
          0,
          0,
          0.5057034220532319,
          1,
          0.7639048545406314,
          1,
          0.5057034220532319,
          0,
          1,
          1,
          1,
          1,
          0.5057034220532319,
          1,
          1,
          0.7639048545406314,
          0,
          0.7417985675126005,
          0.7417985675126005,
          0.7417985675126005,
          0.5057034220532319,
          0.4857193385798921,
          0.2496241931205235,
          0.4857193385798921,
          0.2496241931205235,
          0,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.2496241931205235,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5142806614201079,
          0.5057034220532319,
          0.5142806614201079,
          0.5142806614201079,
          0.7639048545406314,
          0.5142806614201079,
          0.5057034220532319,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0.25607922893270846,
          0.5142806614201079,
          0,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.2496241931205235,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          0,
          0,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0,
          0.49429657794676807,
          0.49429657794676807,
          0.49429657794676807,
          0.49429657794676807,
          0.7439207710672916,
          0.7439207710672916,
          0.49429657794676807,
          0,
          1,
          1,
          0.49429657794676807,
          0.7503758068794766,
          0.7503758068794766,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0.7503758068794766,
          1,
          1,
          1,
          1,
          1,
          0.7503758068794766,
          0.2582014324873994,
          1,
          0,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          0.7417985675126005,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0.7439207710672916,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          0,
          1,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          1,
          0.5142806614201079,
          0.7639048545406314,
          1,
          1,
          0.5057034220532319,
          1,
          0.25607922893270846,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          0.25607922893270846,
          0.7639048545406314,
          1,
          1,
          0.7639048545406314,
          1,
          0.7639048545406314,
          1,
          0.7639048545406314,
          0.7639048545406314,
          0,
          1,
          1,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          1,
          1,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          0.5057034220532319,
          0.7639048545406314,
          1,
          0,
          0.7639048545406314,
          0.5057034220532319,
          1,
          1,
          0.5057034220532319,
          0,
          0.5057034220532319,
          0.7417985675126005,
          0.2496241931205235,
          0,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5078256256079229,
          0.5057034220532319,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0.5142806614201079,
          0.5057034220532319,
          0.7639048545406314,
          0.5142806614201079,
          0.5142806614201079,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0.5142806614201079,
          0,
          0.5142806614201079,
          0.5142806614201079,
          0.5142806614201079,
          0.25607922893270846,
          0,
          0.7639048545406314,
          0.5057034220532319,
          0.2496241931205235,
          0,
          0.5057034220532319,
          0.7639048545406314,
          0.5078256256079229,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0.2496241931205235,
          0.5078256256079229,
          0.5078256256079229,
          0.5078256256079229,
          0.5057034220532319,
          0.2496241931205235,
          0.2496241931205235,
          0.5057034220532319,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0,
          0.49429657794676807,
          0.2582014324873994,
          0.49429657794676807,
          0.49429657794676807,
          0.7439207710672916,
          0.7439207710672916,
          0.7439207710672916,
          0.49429657794676807,
          1,
          0.7439207710672916,
          0.49429657794676807,
          0.7439207710672916,
          1,
          1,
          0.49429657794676807,
          1,
          0.5078256256079229,
          0.7503758068794766,
          0.7503758068794766,
          1,
          1,
          1,
          0.4921743743920771,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7417985675126005,
          1,
          0.5142806614201079,
          1,
          0,
          1,
          0.2582014324873994,
          0.7439207710672916,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.25607922893270846,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5057034220532319,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7503758068794766,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0.7417985675126005,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          0.23609514545936866,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7639048545406314,
          0.4921743743920771,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.23609514545936866,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0.7439207710672916,
          0,
          1,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          0.5057034220532319,
          0.25607922893270846,
          0,
          0,
          1,
          0.7639048545406314,
          0.7639048545406314,
          1,
          0.7639048545406314,
          1,
          0.5057034220532319,
          1,
          0.7639048545406314,
          1,
          1,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          1,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          1,
          0.5057034220532319,
          1,
          0.5057034220532319,
          1,
          0.5057034220532319,
          0.7417985675126005,
          0.7417985675126005,
          0,
          0.2496241931205235,
          0,
          0.5078256256079229,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.25607922893270846,
          0.7639048545406314,
          0,
          0.5142806614201079,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.5057034220532319,
          0.5142806614201079,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0,
          0,
          0.25607922893270846,
          0.5142806614201079,
          0.7639048545406314,
          0.7639048545406314,
          0.2582014324873994,
          0.5142806614201079,
          0.2582014324873994,
          0.7639048545406314,
          0.5057034220532319,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0,
          0.2496241931205235,
          0.7639048545406314,
          0.2496241931205235,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.7639048545406314,
          0.2496241931205235,
          0.2496241931205235,
          0.5057034220532319,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0.2496241931205235,
          0,
          0.2496241931205235,
          0.2496241931205235,
          0,
          0.2582014324873994,
          0.2582014324873994,
          0.49429657794676807,
          0.7439207710672916,
          0.7439207710672916,
          0.7439207710672916,
          0.49429657794676807,
          0.49429657794676807,
          1,
          0.7503758068794766,
          0.7503758068794766,
          0.7503758068794766,
          1,
          1,
          1,
          1,
          0.2582014324873994,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5078256256079229,
          0.5078256256079229,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          1,
          1,
          0,
          0.7439207710672916,
          0.2582014324873994,
          1,
          0.7439207710672916,
          0.7439207710672916,
          0.7439207710672916,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5057034220532319,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0.49429657794676807,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          0.7417985675126005,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          0,
          0.7439207710672916,
          1,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7439207710672916,
          0.7503758068794766,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          0.7439207710672916,
          0.7439207710672916,
          0.7439207710672916,
          0.4921743743920771,
          0,
          0.7639048545406314,
          0.5142806614201079,
          0.5142806614201079,
          1,
          1,
          1,
          1,
          1,
          0.2582014324873994,
          1,
          1,
          1,
          1,
          1,
          0.5057034220532319,
          1,
          1,
          1,
          0.7639048545406314,
          1,
          0.5142806614201079,
          0.5142806614201079,
          0.5142806614201079,
          0,
          0.7639048545406314,
          0.5057034220532319,
          0.5057034220532319,
          1,
          1,
          1,
          0.5057034220532319,
          0.7417985675126005,
          0.7417985675126005,
          0.7417985675126005,
          0.7417985675126005,
          1,
          0.4857193385798921,
          0.7417985675126005,
          0,
          0.7417985675126005,
          0,
          0.7417985675126005,
          0.7417985675126005,
          0.5057034220532319,
          0.7417985675126005,
          0,
          0.4857193385798921,
          0.7417985675126005,
          0.4857193385798921,
          0,
          0.5078256256079229,
          0.5078256256079229,
          0.5078256256079229,
          0.7639048545406314,
          0,
          0.7639048545406314,
          0.7639048545406314,
          0.2582014324873994,
          0.7639048545406314,
          0.7639048545406314,
          0.2582014324873994,
          0,
          0.7439207710672916,
          0.7439207710672916,
          0.2582014324873994,
          0.2582014324873994,
          1,
          0.49429657794676807,
          1,
          0.7439207710672916,
          1,
          0.7503758068794766,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7503758068794766,
          0.7503758068794766,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.7439207710672916,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.4921743743920771,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0
         ]
        },
        {
         "line": {
          "color": "orange",
          "dash": "dash",
          "width": 1
         },
         "mode": "lines",
         "name": "Mean - std",
         "type": "scatter",
         "x": [
          0,
          1477
         ],
         "y": [
          0.5483311501586028,
          0.5483311501586028
         ]
        },
        {
         "line": {
          "color": "red",
          "dash": "dash",
          "width": 1
         },
         "mode": "lines",
         "name": "Mean + std",
         "type": "scatter",
         "x": [
          0,
          1477
         ],
         "y": [
          0.2598618370819814,
          0.2598618370819814
         ]
        }
       ],
       "layout": {
        "font": {
         "color": "#7f7f7f"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Normality scores"
        },
        "xaxis": {
         "title": {
          "text": "Data point"
         }
        },
        "yaxis": {
         "title": {
          "text": "Normality score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot normality scores\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_norm.index,\n",
    "    y=df_norm['Normality score'],\n",
    "    mode='markers',\n",
    "    name='Normality Scores',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "    )\n",
    "))\n",
    "\n",
    "mean = np.mean(df_norm['Normality score'])\n",
    "std = np.std(df_norm['Normality score'])\n",
    "# Plot standard deviation lines\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(df_norm)],\n",
    "    y=[mean - std, mean - std],\n",
    "    mode='lines',\n",
    "    name='Mean - std',\n",
    "    line=dict(\n",
    "        color='orange',\n",
    "        width=1,\n",
    "        dash='dash'\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(df_norm)],\n",
    "    y=[mean - 2* std, mean -2* std],\n",
    "    mode='lines',\n",
    "    name='Mean + std',\n",
    "    line=dict(\n",
    "        color='red',\n",
    "        width=1,\n",
    "        dash='dash'\n",
    "    )\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Normality scores',\n",
    "    xaxis_title='Data point',\n",
    "    yaxis_title='Normality score',\n",
    "    font=dict(\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8f364f4c6a15a98e6f24366f20c415b81f2b82de1c06055d293928a78744407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
